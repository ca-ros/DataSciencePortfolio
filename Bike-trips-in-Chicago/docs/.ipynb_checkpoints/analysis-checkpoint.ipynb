{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.giphy.com/media/l0HluULNylbTu44Ao/giphy.gif)\n",
    "## Introduction\n",
    "\n",
    "In this project, we carry out exploratory analysis of the Divvy dataset by setting out research questions, and then exploring relationship between stations, user behaviors, user types, and bike types to answer those questions.\n",
    "\n",
    "*The project was completed as a part of Google's Data Analytics Professional Certificate online course on Coursera.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## The Data\n",
    "\n",
    "This dataset contains biketrip data in Chicago from year 2020-2021. The data is provided by [Divvy bikes](https://divvybikes.com) according to the [Divvy Data License Agreement](https://ride.divvybikes.com/data-license-agreement).\n",
    "\n",
    "Each trip is anonymized and includes:\n",
    "- Trip start day and time\n",
    "- Trip end day and time\n",
    "- Trip start station\n",
    "- Trip end station\n",
    "- Rider type (Member, Single Ride, and Day Pass)\n",
    "- Rideable type (Casual, Docked, Electric)\n",
    "\n",
    "The data has been processed to remove trips that are taken by staff as they service and inspect the system; and any trips that were below 60 seconds in length (potentially false starts or users trying to re-dock a bike to ensure it was secure).\n",
    "\n",
    "The dataset is wrangled by [Chris](github.com/ca-ros). To know more about data wrangling documentation, visit this [link](https://github.com/ca-ros/divvy-bikeshare/blob/master/docs/data_wrangling.md). This contains stations names with null values and will be filled with data in the future after I have a good grasp in **Machine Learning** and **Web Scraping** by using the stations' coordinates.\n",
    "\n",
    "> To know more about Divvy and the dataset, visit this [link](https://ride.divvybikes.com/system-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "### Research question 1:\n",
    "### Research question 2:\n",
    "### Research question 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 rows of data are:\n",
      "\n",
      "            ride_id  rideable_type           start_time             end_time  \\\n",
      "0  A7CE7984C8A9240F  electric_bike  2021-11-13 17:39:57  2021-11-13 17:44:59   \n",
      "1  BD2F67E4AD0E9309  electric_bike  2021-11-18 14:22:19  2021-11-18 14:25:07   \n",
      "2  923264CBA14F6F8B  electric_bike  2021-08-06 13:17:42  2021-08-06 13:51:27   \n",
      "3  91D17FA839079834  electric_bike  2021-11-06 19:20:18  2021-11-06 19:39:55   \n",
      "4  EF7210BD5C943390  electric_bike  2021-08-16 20:09:51  2021-08-16 20:57:01   \n",
      "\n",
      "   trip_duration  start_station_id      start_station_name  end_station_id  \\\n",
      "0            302               NaN                     NaN             NaN   \n",
      "1            168               NaN                     NaN             NaN   \n",
      "2           2025              44.0  State St & Randolph St             NaN   \n",
      "3           1177               NaN                     NaN             NaN   \n",
      "4           2830              44.0  State St & Randolph St             NaN   \n",
      "\n",
      "  end_station_name user_type  \n",
      "0              NaN    member  \n",
      "1              NaN    member  \n",
      "2              NaN    member  \n",
      "3              NaN    member  \n",
      "4              NaN    casual  \n",
      "\n",
      "\n",
      "\n",
      "Dataset has 8988891 rows and 10 columns\n",
      "\n",
      "\n",
      "\n",
      "Datatype: \n",
      "\n",
      "ride_id                object\n",
      "rideable_type          object\n",
      "start_time             object\n",
      "end_time               object\n",
      "trip_duration           int64\n",
      "start_station_id      float64\n",
      "start_station_name     object\n",
      "end_station_id        float64\n",
      "end_station_name       object\n",
      "user_type              object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "The number of unique values in each column are: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def overview():\n",
    "    data = pd.read_csv(\"trips_p2.csv\")\n",
    "    data.round()\n",
    "    print(\"The first 5 rows of data are:\\n\")\n",
    "    print(data.head(5))\n",
    "    print(\"\\n\\n\\nDataset has {} rows and {} columns\".format(data.shape[0], data.shape[1]))\n",
    "    print(\"\\n\\n\\nDatatype: \\n\")\n",
    "    print(data.dtypes)\n",
    "    print(\"\\n\\n\\nThe number of unique values in each column are: \\n\")\n",
    "    print(data.nunique())\n",
    "    print(\"\\n\\n\\nThe number of null values for each column are: \\n\")\n",
    "    print(data.isnull().sum())\n",
    "    print(\"\\n\\n\\nData summary: \\n\")\n",
    "    print(data.describe())\n",
    "    return data\n",
    "\n",
    "# Lastly, assigning a variable to overview()\n",
    "data = overview()\n",
    "\n",
    "## Note: Uploading this file takes time, took me 5 mins to finish running this block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we see?\n",
    "- The dataset has 8,988,891 rows and 13 columns\n",
    "- We notice null values in station_name column (12.68 % of the data) that will be omitted in analysis\n",
    "- We need to convert columns start_time and end_time into datetime datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change start_time & end_time into datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id                       object\n",
       "rideable_type                 object\n",
       "start_time            datetime64[ns]\n",
       "end_time              datetime64[ns]\n",
       "trip_duration                  int64\n",
       "start_station_id             float64\n",
       "start_station_name            object\n",
       "end_station_id               float64\n",
       "end_station_name              object\n",
       "user_type                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datetime\n",
    "data[['start_time', 'end_time']] = data[['start_time', 'end_time']].apply(pd.to_datetime, format = '%Y-%m-%d %H:%M:%S')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The NaNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows where station names are nulls\n",
    "data.dropna(subset = ['start_station_name', 'end_station_name'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nulls in each column\n",
      "\n",
      "start_station_name    0\n",
      "end_station_name      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The number of nulls in each column\\n')\n",
    "print(data[['start_station_name', 'end_station_name']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking into biketrips over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing start_time\n",
    "data_i = data.set_index('start_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = data_i[[count(ride_id), start_station_name.value_counts()]].plot(figsize=(11, 9), subplots=True, linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9337a79df3e5d869f0c5777e0d2b1209a728c6a52c1d44e22a85de3e5a3843fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
